name: Playwright Scraper

on:
  workflow_dispatch:
    inputs:
      SCRAPER_URL:
        description: 'URL to scrape'
        required: false
        default: 'https://www.sreality.cz/hledani/pronajem/byty/praha?velikost=3%2Bkk'
      SCRAPER_LIMIT:
        description: 'Max number of listings to scrape (total across pages)'
        required: false
        default: '50'
      SCRAPER_PAGE_LIMIT:
        description: 'Optional hard cap on pages (blank = unlimited)'
        required: false
        default: ''
      NAV_TIMEOUT_MS:
        description: 'Navigation timeout per page'
        required: false
        default: '30000'
      ITEM_DELAY_MS:
        description: 'Delay between listing detail fetches (ms)'
        required: false
        default: '1500'
      SCRAPER_CONCURRENCY:
        description: 'How many listings to fetch in parallel'
        required: false
        default: '3'
      HEADLESS:
        description: 'Run in HEADLESS mode (true/false)'
        required: false
        default: true

jobs:
  scrape:
    runs-on: ubuntu-latest

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4

      # ---------- Cache npm (faster installs) ----------
      - name: Cache npm cache
        uses: actions/cache@v4
        with:
          path: ~/.npm
          key: ${{ runner.os }}-npm-${{ hashFiles('**/package-lock.json') }}
          restore-keys: |
            ${{ runner.os }}-npm-

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '22.x'
          cache: 'npm'

      - name: Install Node.js dependencies
        run: npm ci

      - name: Fetch previous URLs from Notion
        run: node scripts/fetchNotionUrls.js
        env:
          NOTION_TOKEN: ${{ secrets.NOTION_TOKEN }}
          NOTION_DB_ID: ${{ secrets.NOTION_DB_ID }}

      # ---------- Resolve Playwright version for a stable cache key ----------
      - name: Get Playwright version
        id: pwv
        run: |
          echo "version=$(node -p "require('./package.json').dependencies?.playwright || require('./package.json').devDependencies?.playwright || 'unknown'")" >> $GITHUB_OUTPUT

      # ---------- Cache Playwright browser binaries ----------
      - name: Cache Playwright browsers
        uses: actions/cache@v4
        with:
          path: ~/.cache/ms-playwright
          key: ${{ runner.os }}-ms-playwright-${{ steps.pwv.outputs.version }}
          restore-keys: |
            ${{ runner.os }}-ms-playwright-

      - name: Install Playwright browsers (chromium)
        run: npx playwright install chromium

      # ---------- Run scraper ----------
      - name: Download artifact from last successful run
        uses: dawidd6/action-download-artifact@v6
        with:
          workflow: scraper.yaml   # name of your workflow file
          name: scraped-results
          path: scripts/prev/
        continue-on-error: true  # first run will have nothing;

      - name: Run scraper
        run: node scripts/scraper.js
        env:
          CI: true
          SCRAPER_URL: ${{ github.event.inputs.SCRAPER_URL }}
          SCRAPER_LIMIT: ${{ github.event.inputs.SCRAPER_LIMIT }}
          SCRAPER_PAGE_LIMIT: ${{ github.event.inputs.SCRAPER_PAGE_LIMIT }}
          NAV_TIMEOUT_MS: ${{ github.event.inputs.NAV_TIMEOUT_MS }}
          ITEM_DELAY_MS: ${{ github.event.inputs.ITEM_DELAY_MS }}

      # ---------- Upload results ----------
      - name: Upload scraped results
        if: success()   # only if scraper didnâ€™t fail
        uses: actions/upload-artifact@v4
        with:
          name: scraped-results
          path: scripts/results.json
          retention-days: 7